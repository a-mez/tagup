I was given a dataset containing data generated by twenty different machines measuring four different features, with the objective of converting the data points into a format that is compatible with the machine learning pipeline at Tagup. I chose to format the data as an xarray Dataset. An xarray Dataset contains one or more DataArrays that correspond to the dependent variables, which are indexed by coordinates corresponding to the independent variables. This makes the format well-suited for a observational data such as the original dataset.

The original database included data from twenty machines which each generated 3,000 data points in time, giving a total of 60,000 data points. Each data point had four features named feat_0, feat_1, feat_2, and feat_3. The SQL database contained one table for each feature. In addition to this, there was a table of static data describing the installation date, model, and room of each machine. After examining the data to find the table names, column names, number of data points, and so on, I loaded each of the tables into Python as an array using Python's SQLite library.

I began by designing the coordinate system. Because each value can be uniquely determined by the machine and timestamp, it is sufficient to create a list of timestamps and machines to identify the different data points. In order to do this, loaded the timestamps from the feat_0 table and converted them into the pandas Timestamp format and I created a list of machines from Machine 0 to Machine 19.

Once the coordinate lists were created, the next step was to convert the data from one a one-dimensional list into a two-dimensional array. Because the dataset relatively small and already ordered by machine then timestamp, this was simple to accomplish by iterating through the list of data points. If the data was disorganised then I would have needed to first run a sorting algorithm and if the dataset was much larger, it may have been useful to research whether or not there are more efficient ways to sort the data. However, neither of those steps were necessary here.

After the data was organized into two-dimensional arrays, I began to remove the outliers. The most obvious approach would be to use a measure such as the interquartile range or the standard deviation of the data to identify unrealistically large data points, but I chose not to do this because the output of each machine is not consistent across the dataset. Each machine has three stages: pre-failure, failure, and post-failure, and the data output is wildly different during each stage. If I had used the standard deviation for the whole dataset, it may have led to me omitting early data points that are not actually outliers and missing later data points that are outliers. To deal with this, I decided to use a rolling standard deviation instead, so that only nearby points would be considered for determining outliers. While this may cause some problems near the borders between the different stages of the machines' life, it would not cause significant problems for early data points before the machines fail or late data points after the machines fail.

After identifying and removing outliers, I replaced them with the mean of the nearby data points so that there would not be missing data in the dataset. I chose to use the four nearest data points rather than the two nearest in case there is a sequence of three outliers in a row and weighted the average so that the closer data points would matter more than the further data points. While it is sometimes recommended to use the median instead of the mode for replacing outliers since outliers influence the mean more than the median, I did not think that this was necessary since any outliers had already been removed.

Finally, I assembled the data into an xarray Dataset.

Next, I created a Dataset containing the static data. The static data is only one dimensional and each data point is identifiable by the machine id. While a Dataset is maybe more complicated than necessary for this data and a simpler data structure like a dictionary would have probably been enough, I chose to use a Dataset anyway in order to keep this data compatible with Tagup's machine learning pipeline.

However, there are two additional important data points that were not included in the initial database: the time when each machine began to fail and the time when each machine fully failed. Based on my exploratory data analysis in the console, when each machine began to fail, the rolling standard deviation would fall slightly before sharply rising. Because of this, I decided to defining the beginning of failure as the timestamp after the rolling standard deviation rises or falls for ten consecutive datapoints. I to do this after rising or falling instead of before because the of the way the rolling standard deviations works: when the standard deviation begins falling, it will affect the rolling standard deviation a few datapoints early, so those datapoints should be ignored. I defined the end of failure as the point the value of every remaining value is below 1.0. This was a straightforward choice that accurately reflects each machine's situation.

I added these two features to the static data so that I could easily see when each machine failed.

Next I used MatPlotLib to create graphs of the data generated by each machine.

Finally, I created arrays of the means and standard deviations of each machine before, during, and after failure. I did this by looking up the time of failure of each machine from the static data, using it to filter the out the correct subsets of the data, and finally calculating the mean and standard deviation. One notable thing that requires more attention is that the data for feature 3 appears to contain a few outliers that were not filtered out by the rolling standard deviation. I did not have time to examine this more closely, but I believe it deserves more attention.
